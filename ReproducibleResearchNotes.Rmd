---
title: "Reproducible Research"
author: "LKB"
date: "Sunday, June 14, 2015"
output: html_document
---

#Week 1

Replication of results is most important in science. But it is challenging to replicate the study so lets make the code & data available so others can replicate the study analysis and understand the research.
A lot of times research is done using complex statistical methods and should be open to scrutiny, as a lot of stake-holders and money are involved.

Research pipeline:

* measured data
* Analytic
* compute results
* present
  * figures
	* tables
	* numerical summaries
* article

Recommendations from IOM report:

* publicity available data/metadata from research and computer code


What do we need:

* analytic data and code is available
* documentation is available
* standard means of distribution

##Structure of data analysis

* define the question
	* the better question the clearer the path
	* sometimes you just explore dataset
	* there should be scientific context, its not random
* define ideal data set
	* depends on your goal
	* is your goal:
		* descriptive 		whole population
		* exploratory			random pop, a lot of variables
		* inferential 		right pop, random sampling
		* predictive			training and test set from pop
		* casual					data from a randomized study
		* mechanistic			data about all components of the system
* determine what data can you access
	* how can u get it
	* how much will it cost ect
	* how can u create data
* obtain and clean the data
	* understand the source of data
	* understand how it was processed
	* **determine if data is good enough**
	* record all steps in the script
* exploratory data analysis
	* summaries
	* is any data missing? Why?
	* nice trick: log data and +1 so u can see in boxplot more clearly -- this is for analysis only ! 
	* relationship between predictors
	* clustering
* statistical prediction/modelling
	* measure uncertainty
* interpreting results
	* use proper language
	* give explanation
* CHALLENGE ALL RESULTS
	* why is this best answer/model/data ? ect
* synthesise/write up results
	* tell story, address the challenge
	* address the question you have been asking
	* include "pretty" figures
* created reproducible code


##Organising Data Analysis

* Data
	* raw and processed
	* include URL+data accessed
	* processed data should be TIDY
* Figures
	* exploratory figures are fast and simple -- its about understanding
	* final figures need to be polished -- its probably 5 fig out of much larger number
* Script code
	* may be less commended 
	* some of this unused
	* final scripts should be commended and cleaned
	* indicate what was not used
* text
	* read me files
	* dont seprarete docs and code
	* final document


# Week 2 -- Tools

How to make work reproducible?

* decide what to do
* keep track of things (Ver Control)
* use code based soft
* don't save output
* use non-proprietary format

#Markdown

* simple version of markup languages
* focus on writing not formatting
simple to use & easy to integrate with programming language
* text 2 HTML conversion tool
* newline require double space after EOL

R markdown have a few differences

* its coupling of R and markdown
* it makes literate statistical programming
* R code in the document works, as it was eval to make doc

Tools to create outputs:

* *slidify* for slides
	* R markdown -> markdown -> HTML
* knitr

##knitr

This is a new library for making R markdown, made by Yihui Xie

###What is it useful for:

* manuals
* short to med size tech docs
* tutorials
* reports

###What is it not useful for:

* v long research articles
* complex time-consuming docs
* docs that require precise formatting


###Command line driven way of creating 

```{r}
library(knitr)
setwd(<cwd>)
knit2html("doc.Rmd")
browseURL("doc.html")
```




###How does it work

knitr will produce markdown doc with both code and calculated results of the code. Then we crated html docs.

Notes:

* code chunks can have names {r Name1}
* for figs you can define height {r, fig.heigh=4} ; fig.width
* define if you want to see output
  * set results: "asis", "hide"
* figs are embeded into html
* you can cache computations (cache =  TRUE)\
  * dependencies are not explicitly tracked
* you can make table with xtable

```{r table, results ='asis'}

library(datasets)
data(airquality)
library(xtable)

fit <- lm(Ozone ~ Wind + Temp + Solar.R, data = airquality)

#tables
xt <- xtable(summary(fit))
print(xt, type = "html")

```


###Global options

```{r setoptions, echo = FALSE}
library(knitr)
opts_chunk$set(echo = FALSE, results = "hide")
```

#Week 3 communicating results

* ppl are busy
* results are presented graphically, and usually first intro is by email
* granuality/detail level vary, and its useful to break results this way

Getting email responses from busy ppl

* Try to send no more than one email a day. 
*  whole email in the subject line or top 3 sentences
* If you need information, ask yes or no questions
* if it is time sensitive, state the default action if no response by specified 
* Be as specific as you can 
* include obvious keywords people can use to search for your email  

Email:

* topic - summarise ur research
* body
  * A brief description of the problem / context -- what was proposed and executed;
  * summarize findings / results; 1-2 paragraphs
  * If action needs suggest some concrete options
  * Any questions should be yes / no
* attachments
  * markdowns
* links -- github ect



##Checklist:

* start with good science
  * garbage in -- grabage out
  * good collaborators einforces good practice
* DON'T do things by hand
* DON'T GUI, use scripts
  * sometimes you can produce log
* teach PC how to do it
* use VC -- this will slow u down and get u thinking
* keep track of ur software enviroment
  * PC architecture
  * OS
  * software chain
  * supporting soft
  * external dependences
  * version numbers
  * just use *sessionInfo()*
* DONT save output
  * save code and data that generated output
  * during project keep temp files
  * for documentation make sure u got code to create A-Z
* keep the same seeds -- *set.seed()*
* think about whole papeline
  * how far can we go until results are not reproducible


#Week 4


```{r, echo=FALSE}
setwd("d:/tmp/Dropbox/Edu/Coursea/DataScienceSpecialization/ReproducibleResearch/")

require(knitr)
opts_chunk$set(echo = TRUE, cache = TRUE, cache.path = "cache/", fig.path = "figure/")
```


#Caching computation

```{r}
library(datasets)
library(stats)


data(airquality)

#fit ln model
fit <- lm(Ozone ~ Wind + Temp + Solar.R, data = airquality)
summary(fit)

#plot some diagostics
par(mfrow = c(2,2))
plot(fit)
```






#Useful docs:

* <http://projecttemplate.net/>
* <http://www.r-statistics.com/2010/09/managing-a-statistical-analysis-project-guidelines-and-best-practices/>
* <http://biostatistics.oxfordjournals.org/content/10/3/405.full>
* <http://simplystatistics.org/2012/02/27/the-duke-saga-starter-set/>
